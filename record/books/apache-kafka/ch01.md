# 아파치카프카 애플리케이션 프로그래밍 with 자바

## ch01. 들어가며

### 1.1 카프카의 탄생

### 1.2 빅데이터 파이프라인에서 카프카의 역할

- 데이터 레이크
  - 데이터가 모이는 저장 공간.
  - data warehouse 와 다르게 필터링되거나 패키지화 되지 않은 데이터가 저장 됨.
- 데이터 파이프라이닝
  - 엔드 투 엔드 방식의 데이터 수집 및 적재를 개선하고 안정성을 추구하며, 유연하면서도 확장 가능하게 자동화한 것.

#### 높은 처리량

- 많은 양의 데이터를 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그데이터를 처리하는 데 적합.
- 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리
- 파티션 개수만큼 컨슈머 개수를 늘려서 동일 시간당 데이터 처리량을 늘림

#### 확장성

- 데이터 파이프라인에서 데이터를 모을 때 데이터가 얼마나 들어올지는 예측하기 어렵다.
- 데이터가 많아지면 클러스터의 브로커 개수를 자연스럽게 늘려 스케일 아웃 할 수 있다.

#### 영속성

- 영속성이란 데이터를 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성
- 카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다.
- 운영체제에서는 파일 I/O 성능 향상을 위해 페이지 캐시 영역을 메모리에 따로 생성하여 사용.
- 페이지 캐시 메모리 영역을 사용하여 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식이기 때문에 카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량이 높다.
- 브로커 애플리케이션이 장애 발생으로 종료되어도 프로세스를 재시작하여 안전하게 데이터를 다시 처리.

#### 고가용성

- 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리
  - min.insync.replicas 옵션
- 클러스터로 이루어진 카프ㅏ는 데이터의 복제(replication)을 통해 고가용성의 특징을 가지게 됨.
- 프로듀서로 전송받은 데이터를 여러 브로커 중 1대의 브로커에만 저장하는 것이 아니라 또 다른 브로커에도 저장
- 온프레미스 환경의 서버 랙 또는 퍼블릭 클라우드의 리전 단위 장애에도 데이터를 안전하게 복제할 수 있는 브로커 옵션들이 준비되어 있음.

### 1.3 데이터 레이크 아키텍처와 카프카의 미래

- 데이터 레이크 아키텍처
  - 람다 아키텍처
  - 카파 아키텍처

- 람다 아키텍처
  - 레거시 데이터 수집 플랫폼을 개선하기 위해 구성한 아키텍처
  - 배치 레이어를 모아서 특정 시간, 타이밍마다 일괄 처리
  - 서빙 레이어는 가공된 데이터를 데이터 사용자, 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간.
  - 스피드 레이어는 서비스에서 생성되는 원천 데이터를 실시간으로 분석하는 용도
  - 배치 데이터에 비해 낮은 지연으로 분석이 필요한 경우에 스피드 레이어를 통해 데이터를 분석한다.
  - 스피드 레이어에서 가공, 분석된 실시간 데이터는 사용자 또는 서비스에서 직접 사용할 수 있지만 필요한 경우에는 서빙 레이어로 데이터를 보내서 저장하고 사용 할 수 있다.
  - 람다 아키텍처에서 카프카는 스피드 레이어에 위차
  - 서비스 애플리케이션들의 실시간 데이터를 짧은 지연시간으로 처리, 분석 할 수 있다
  - 데이터 처리 방식을 명확히 나눌 수 있었지만 레이어가 2개로 나뉘기 때문에 생기는 단점이 있다. 데이터를 분석, 처리하는 데에 필요한 로직이 2벌로 각가의 레이어에 따로 존재해야 한다는 점과 배치 데이터와 실시간 데이터를 융합하여 처리할 때는 다소 유연하지 못한 파이프라인을 생성해야 한다는 점이다.

- 카파 아키텍처
  - 람다 아키텍처와 유사하지만 배치 레이어를 제거하고 모든 데이터를 스피드 레이어에 넣어서 처리한다는 점이 다르다.
  - 람다 아키텍처에서 단점으로 부각되었던 로직의 파편화, 디버깅, 배포, 운영 분리에 대한 이슈를 제거하기 위해 배치 레이어를 제거한 카파 아키텍처는 스피드 레이어에서 데이터를 모두 처리할 수 있었으므로 엔지니어들은 더욱 효율적으로 개발과 운영에 임할 수 있게 되었다.
  - 카파 아키텍처는 스피드 레이어에서 모든 데이터를 처리하므로 서비스에서 생성되는 모든 종류의 데이터를 스트림 처리해야 한다.
  
- 배치 데이터와 스트림 데이터
  - '배치 데이터'는 초, 분, 시간, 일 등으로 한정된 기간 단위 데이터
  - 배치 데이터는 일괄 처리(batch processing)하는 것이 특징
  - 인터넷 쇼핑몰에서 지난 1분간 주문한 제품 목록, 2021년 신입생 목록이 배치 데이터
  - '스트림 데이터'는 한정되지 않은 데이터로 시작 데이터와 끝 데이터가 명확히 정해지지 않은 데이터를 뜻한다.
  - 각 지점의 데이터는 보통 작은 단위로 쪼개져 있으며 웹 사용자의 클릭 로그, 주식 정보, 사물 인터넷의 센서 데이터를 스트림 데이터라고 볼 수 있다.

- 배치 데이터를 스트림 프로세스로 처리할 수 있게된 이유
  - 모든 데이터를 로그로 바라보는 것에서 시작
  - 여기서 로그는 애플리케이션을 로킹하는 텍스트 로그가 아닌 데이터의 집합
  - 이 데이터는 지속적으로 추가가 가능하며 각 데이터에는 일정한 번호(또는 타임 스탬프)가 붙는다

- 로그는 배치 데이터를 스트림으로 표현하기에 적합.
- 일반적으로 데이터 플랫폼에서 배치 데이터를 표현할 때는 각 시점의 전체 데이터를 백업한 스냅샷 데이터를 뜻했다.
- 배치 데이터를 로그로 표현할 때는 각 시점의 배치 데이터의 변환 기록을 시간 순서대로 기록함으로써 각 시점의 모든 스냅샷 데이터를 저장하지 않고도 배치 데이터를 표현
- 로그로 배치 데이터와 스트림 데이터를 저장하고 사용하기 위해서는 변환 기록이 일정 기간동안 삭제되어서는 안 되고 지속적으로 추가되어야 한다.
- 서비스에서 생성된 모든 데이터가 스피드 레이어에 들어오는 것을 감안하면 스피드 레이어를 구성하는 데이터 플랫폼은 SPOF가 될 수 있으므로 반드시 내결함성과 장애 허용 특징을 지녀야 했다.
- 2020년 카프카 서밋에서 제이 크랩스는 카파 아키텍처에서 서빙 레이어를 제거한 아키텍처인 스트리밍 데이터 레이크를 제안했다.
- 카파 아키텍처를 살펴 보면 데이터를 사용하는 고객(데이터 사이언티스트, 데이터 엔지니어 등)을 위해 스트림 데이터를 서빙 레이어에 저장하는 것을 알 수 있다.
- 서빙 레이어는 하둡 파일 시스템, 오브젝트 스토리지와 같이 데이터 플랫폼에서 흔히 사용되는 저장소이다.
- 스피드 레이어로 사용되는 카프카에 분석과 프로세싱을 완료한 거대한 용량의 데이터를 오랜 기간 저장하고 사용할 수 있다면 서빙 레이어는 제거되어도 된다. 오히려 서빙 레이어와 스피드 레이어가 이중으로 관리되는 운영 리소스를 줄일 수 있는 것이다.
- 스피드 레이어에서 데이터를 분석, 프로세싱, 저장함으로써 단일 진실 공급원이 되는 것이다.
- 데이터가 필요한 모든 고객과 서비스 애플리케이션은 스트리밍 데이터 레이크의 스피드 레이어만 참조함으로써 데이터의 중복, 비정합성과 같은 문제에서 벗어날 수 있다.
- 아직은 카프카를 스트리밍 데이터 레이크로 사용하기 위해 개선해야 하는 부분이 있다.
- 자주 접근하지 않는 데이터를 굳이 비싼 자원(브로커의 메모리, 디스크)에 유지할 필요가 없다.
- 카프카 클러스터에 자주 접근하지 않는 데이터는 오브젝트 스토리지와 같이 저렴하면 서도 안전한 저장소에 옮겨 저장하고 자주 사용하는 데이터만 브로커에서 사용하는 구분 작업이 필요하다.
- 카프카 클러스터가 단계별 저장소를 가질 수 있도록 추가 기능을 개발하고 있음.
- 컨플루언트에서 카프카의 데이터를 sql 기반으로 조회할 수 있도록 카프카 스트림즈를 추상화한 ksqlDB를 오픈소스로 제공.
- 카프카와 ksqlDB를 사용한다면 제이 크렙스가 제안한 스트리밍 데이터 레이크에 가장 근접한 모습.
- 하지만 ksqlDB는 아직 타임스탬프, 오프셋, 파티션 기반 쿼리를 제공하지 않기 때문에 배치 데이터를 완벽히 처리하기에는 부족.
- 이외에도 아파치 스파크 스트리밍, 프레스토, 아파치 드릴, 하이브/스파크 SQL 등을 조합하는 방식도 스트리밍 데이터 레이크로 사용하는 방법이라 볼 수 있다.
- 하지만 모든 데이터 형태와 포맷을 지원하는 것은 아니므로 앞으로 추가적인 기능 개발이 필요.
- 카프카가 스트리밍 데이터 레이크로 완성 될 수 있도록 주변 데이터 플랫폼 어플리케이션들이 개발 완료된다면, 가까운 미래에는 카프카를 사용하는 것이 데이터 레이크를 사용하는 것과 동일한 의미를 가질 것이다.

### 1.4 정리
- 데이터 처리량이 많은 대기업이나 은행에서나 카프카를 운영할 것 같지만, 오히려 데이터양이 적은 스타트업에서도 유용하게 사용될 수 있다.
- 스타트업은 비교적 성장 속도가 빠르다고 볼 수 있는데 카프카를 사용하면 이러한 빠른 성장 속에서도 데이터 관련 작업을 안정적으로 확장 가능.
- 이미 데이터 파이프라인이 복잡한 레거시 아키텍처를 가지고 있는 기업이더라도 손쉽게 카프카와 연동할 수 있고 고도화할 수 있다.
